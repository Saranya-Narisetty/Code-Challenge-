{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8174a4-590f-4995-8e84-cd502971d53d",
   "metadata": {},
   "source": [
    "# Given a dataset of customer reviews, preprocess the text and use a pre-trained transformer model (e.g., distilbert-base-uncased) to classify a few sample reviews as positive or negative sentiment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04679123-81bd-416a-b2db-fbed29498190",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Sample dataset:\n",
    "pythonCopyEditreviews = [    \"This product is amazing! I loved it.\",    \"Terrible experience, the quality is so bad.\",    \"Pretty decent, not too great but not too bad either.\",    \"I will never buy this again. Waste of money!\",    \"Exceeded my expectations. Highly recommended!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be236f9c-33fb-4165-9758-b4ad71133318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4834cfe0-a313-4315-a0d7-9093400160c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91991\\anaconda3\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91991\\anaconda3\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91991\\anaconda3\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading necessary nltk data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e458d7-d69f-4f61-a165-4c2feca12f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of customer reviews as sample text data\n",
    "reviews = [\n",
    "    \"The product quality is amazing! I love it.\",\n",
    "    \"Absolutely terrible experience. The service was bad.\",\n",
    "    \"Great product and fast delivery. Highly recommended!\",\n",
    "    \"The product was okay, but I expected better quality.\",\n",
    "    \"Worst experience ever. Never buying again.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e75eba-90db-4991-8e22-d6162b266bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91991\\anaconda3\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c64bdf4-15a1-4765-9b38-e0b7218ac601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing stopwords from the link corpus and wordnet lemmatizer \n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocess and clean the text\n",
    "cleaned_words = []\n",
    "for review in reviews:\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(review.lower())  # Convert to lowercase for uniformity\n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    # Remove stop words and perform lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    cleaned_words.extend(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3162f33b-d602-4581-a8d7-6014efa4d43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\91991\\anaconda3\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ed1bd75-7d8c-4ec7-90b5-9359a6b4c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting word frequencies using the counter class from collections \n",
    "word_counts = Counter(cleaned_words)\n",
    "most_common_words = word_counts.most_common(10)  # Get the top 10 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00fb7088-2208-4ffa-8f26-0998f5c4c575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Words:\n",
      "product: 3\n",
      "quality: 2\n",
      "experience: 2\n",
      "amazing: 1\n",
      "love: 1\n",
      "absolutely: 1\n",
      "terrible: 1\n",
      "service: 1\n",
      "bad: 1\n",
      "great: 1\n"
     ]
    }
   ],
   "source": [
    "# Printing the most common words and their frequencies \n",
    "print(\"Most Common Words:\")\n",
    "for word, count in most_common_words:\n",
    "    print(f\"{word}: {count}\") # Display each word with its corresponding count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1595e414-45d2-4896-8658-e31143df79ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
